DOCUMENT HEADER
VERSION - 1.0
STATUS - Active
COMPLIANCE - 6-Rule Framework Verified
LAST UPDATED - January 2026
CHARACTER COUNT - 14345

PURPOSE

This knowledge base provides the Neural Data Science Agent with comprehensive experimental design methodology including randomization strategies, sample size planning, and best practices for valid marketing experiments.

EXPERIMENTAL DESIGN FUNDAMENTALS

Understanding controlled experimentation.

EXPERIMENT PURPOSE

Why experiments matter.

Causal inference
- Establishes causation
- Eliminates confounding
- Unbiased estimates
- Decision foundation

Optimization learning
- Test variations
- Identify improvements
- Measure effects
- Continuous improvement

Validation
- Confirm hypotheses
- Verify assumptions
- Check predictions
- Build confidence

EXPERIMENTAL PRINCIPLES

Core design principles.

Control
- Comparison baseline
- Counterfactual estimate
- Fair comparison
- Effect isolation

Randomization
- Random assignment
- Bias elimination
- Balance achievement
- Validity foundation

Replication
- Multiple units
- Statistical power
- Variability assessment
- Generalization support

RANDOMIZATION STRATEGIES

Methods for treatment assignment.

SIMPLE RANDOMIZATION

Basic random assignment.

Coin flip method
- Equal probability
- Independent assignment
- Simple implementation
- Potential imbalance

Simple randomization properties
- Unbiased in expectation
- Variability in balance
- Large sample improvement
- Small sample concern

STRATIFIED RANDOMIZATION

Balance on covariates.

Stratification concept
- Divide by strata
- Randomize within
- Guaranteed balance
- Variance reduction

Stratification variables
- Key confounders
- Prognostic factors
- Sample characteristics
- Practical groupings

Implementation
- Strata definition
- Within-strata assignment
- Verification
- Analysis implications

BLOCK RANDOMIZATION

Fixed block assignment.

Block concept
- Fixed size blocks
- Predetermined allocation
- Balance guarantee
- Sequence concealment

Block sizes
- Even block sizes
- Variable blocks
- Concealment consideration
- Implementation trade-offs

MATCHED PAIR DESIGN

Unit matching approach.

Pairing methodology
- Match similar units
- Assign within pairs
- Reduce variability
- Improve precision

Matching criteria
- Key characteristics
- Pre-treatment outcomes
- Geographic similarity
- Business relevance

SAMPLE SIZE PLANNING

Determining required sample.

POWER ANALYSIS

Statistical power calculation.

Power concept
- Probability of detection
- Given true effect
- Conventional threshold 80 percent
- Higher for critical tests

Power determinants
- Effect size
- Sample size
- Significance level
- Variability

Power calculation
- Specify parameters
- Apply formula
- Solve for unknown
- Sensitivity analysis

EFFECT SIZE SPECIFICATION

Defining detectable difference.

Minimum detectable effect
- Smallest relevant difference
- Business significance
- Practical consideration
- Feasibility trade-off

Effect size types
- Absolute difference
- Relative difference
- Standardized effect
- Context-appropriate

Prior information
- Historical data
- Literature review
- Expert judgment
- Conservative assumption

SAMPLE SIZE FORMULAS

Calculation approaches.

Two-sample proportion
- Conversion rate comparison
- Normal approximation
- Formula application
- Sample per arm

Two-sample mean
- Continuous outcome
- Variance estimate
- Standard formula
- Equal allocation

Unequal allocation
- Treatment-control ratio
- Practical considerations
- Power implications
- Formula adjustment

FACTORIAL DESIGNS

Testing multiple factors.

FULL FACTORIAL

All factor combinations.

Full factorial concept
- Every combination tested
- Interaction estimation
- Complete information
- Resource intensive

Factor and level notation
- Factors as variables
- Levels as values
- Cell specification
- Effect coding

Main effects and interactions
- Factor effect averaging
- Interaction identification
- Effect decomposition
- Complete analysis

FRACTIONAL FACTORIAL

Efficient factor testing.

Fractional design concept
- Subset of combinations
- Reduced resources
- Aliasing tradeoff
- Screening focus

Resolution definition
- Confounding pattern
- Higher is better
- Main effect clarity
- Interaction confounding

Selection process
- Design generators
- Alias structure
- Resolution choice
- Standard designs

A/B TESTING

Digital experiment methodology.

A/B TEST DESIGN

Standard A/B approach.

Test setup
- Control variant A
- Treatment variant B
- Random assignment
- Equal allocation

Metric selection
- Primary metric
- Secondary metrics
- Guardrail metrics
- Success criteria

Duration planning
- Power-based duration
- Business cycles
- Seasonality consideration
- Practical constraints

MULTI-VARIANT TESTING

Beyond two variants.

MVT design
- Multiple treatments
- Single control
- Simultaneous testing
- Efficient exploration

Analysis approaches
- Control versus each treatment
- Multiple comparison adjustment
- Best variant selection
- Bayesian approaches

SEQUENTIAL TESTING

Continuous monitoring.

Sequential methods
- Monitor during test
- Early stopping rules
- Adjusted significance
- Efficiency gains

Stopping boundaries
- O'Brien-Fleming bounds
- Pocock bounds
- Alpha spending
- Type I error control

MARKETING EXPERIMENT APPLICATIONS

Experiments in marketing context.

CAMPAIGN EXPERIMENTS

Marketing campaign testing.

Creative testing
- Ad variant comparison
- Message testing
- Visual element testing
- CTA optimization

Audience testing
- Targeting comparison
- Segment validation
- Lookalike evaluation
- Exclusion testing

Channel testing
- Channel effectiveness
- Budget allocation
- Media mix testing
- Incrementality measurement

WEBSITE EXPERIMENTS

Digital experience optimization.

Landing page tests
- Layout optimization
- Copy testing
- Form optimization
- Conversion improvement

User experience tests
- Navigation testing
- Feature testing
- Funnel optimization
- Engagement improvement

ANALYSIS METHODOLOGY

Experiment analysis approaches.

EFFECT ESTIMATION

Calculating treatment effects.

Intent-to-treat analysis
- Analyze as assigned
- Conservative estimate
- Preserves randomization
- Primary analysis

Per-protocol analysis
- Analyze as received
- Compliant only
- Selection concerns
- Secondary analysis

STATISTICAL TESTING

Inference procedures.

Hypothesis testing
- Null formulation
- Test statistic
- P-value calculation
- Decision rule

Confidence intervals
- Effect uncertainty
- Practical interpretation
- Complements testing
- Decision support

AGENT APPLICATION GUIDANCE

Integration patterns for experimental design.

EXPERIMENT WORKFLOW

Standard experiment process.

Design phase
- Objective definition
- Sample size calculation
- Randomization plan
- Analysis specification

Execution phase
- Randomization execution
- Treatment delivery
- Monitoring
- Quality assurance

Analysis phase
- Data collection
- Effect estimation
- Significance testing
- Interpretation

CROSS-AGENT INTEGRATION

Experiment outputs for downstream agents.

Outputs to NDS Agent
- Incrementality estimates
- Calibration data
- MMM validation
- Attribution adjustment

Outputs to ANL Agent
- Effect estimates
- Prediction inputs
- Scenario data
- Confidence bounds

Outputs to PRF Agent
- Performance effects
- Optimization results
- Benchmark data
- Decision support

VERSION HISTORY

Version 1.0 - January 2026 - Initial release with comprehensive experimental design methodology
