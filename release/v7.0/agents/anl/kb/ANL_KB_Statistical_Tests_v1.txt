ANL KNOWLEDGE BASE - STATISTICAL TESTS v1
VERSION: 1.0
STATUS: Production Ready
COMPLIANCE: 6-Rule Compliant

================================================================================
SECTION 1 - INCREMENTALITY TESTING
================================================================================

INCREMENTALITY DEFINITION

Incrementality measures the true causal impact of marketing. It answers: How many conversions would NOT have happened without this marketing activity?

FORMULA
Incremental_Conversions = Total_Conversions - Baseline_Conversions
Incremental_Lift_Percent = (Incremental_Conversions / Baseline_Conversions) x 100
iROAS = (Incremental_Revenue - Marketing_Spend) / Marketing_Spend

GEO-LIFT TESTING

METHODOLOGY
Divide geographic regions into test and control groups. Run advertising in test regions, withhold in control. Compare outcomes.

TEST DESIGN
1. Define KPI (revenue, conversions, etc.)
2. Select test and control geographies
3. Match on historical performance
4. Determine test duration (typically 4 to 8 weeks)
5. Calculate required minimum detectable effect
6. Run test with strict geographic targeting
7. Measure lift between test and control

FORMULA
Lift = (Test_KPI - Control_KPI) / Control_KPI x 100
iROAS = ((Test_Revenue - Control_Revenue) - Test_Spend) / Test_Spend

SYNTHETIC CONTROL METHOD
When perfect control markets are unavailable:
1. Create synthetic control from weighted combination of non-test markets
2. Match synthetic control to test market on pre-test period performance
3. Compare actual test performance to synthetic control prediction
4. Difference is estimated causal lift

HOLDOUT TESTING

METHODOLOGY
Randomly assign users to test (exposed to advertising) and control (not exposed). Compare conversion rates.

USER-LEVEL HOLDOUT
- 90 percent exposed, 10 percent holdout
- Requires ability to suppress ads to holdout users
- Measures true user-level incrementality

GEO HOLDOUT
- Select markets to receive no advertising
- Simpler to implement than user-level
- Market-level analysis

CALCULATION
Incremental_Conversion_Rate = Test_CVR - Control_CVR
Lift_Percent = (Test_CVR - Control_CVR) / Control_CVR x 100

TEST DURATION AND POWER

MINIMUM TEST DURATION
- 4 weeks absolute minimum
- 6 to 8 weeks recommended
- Longer for low conversion volume businesses

POWER ANALYSIS
To detect a 10 percent lift with 80 percent power:
- Need sufficient baseline conversions in control
- Typically 1000 plus conversions in control period
- Higher variance requires longer tests or larger holdout

FORMULA FOR MINIMUM SAMPLE SIZE
n = (Z_alpha + Z_beta)^2 x 2 x p x (1 - p) / d^2

Where:
- Z_alpha = 1.96 for 95 percent confidence
- Z_beta = 0.84 for 80 percent power
- p = baseline conversion rate
- d = minimum detectable effect

INTERPRETING INCREMENTALITY RESULTS

HIGH iROAS (greater than 3x)
- Channel is highly incremental
- Consider increasing investment
- Validate with additional tests

MODERATE iROAS (1.5x to 3x)
- Channel is incremental
- Maintain or cautiously increase
- Monitor for saturation

LOW iROAS (1x to 1.5x)
- Channel is marginally incremental
- Evaluate against alternatives
- May be near saturation

NEGATIVE OR ZERO iROAS
- Channel may not be incremental
- Consider reducing or eliminating
- Investigate potential cannibalization

AGENT GUIDANCE
- Recommend incrementality testing for channels exceeding 30 percent of budget
- Use holdout results to calibrate projection models
- Acknowledge that incrementality can vary by campaign and timing

================================================================================
SECTION 2 - STATISTICAL SIGNIFICANCE FUNDAMENTALS
================================================================================

KEY CONCEPTS

NULL HYPOTHESIS (H0)
There is no difference between test and control groups.
Default assumption until evidence proves otherwise.

ALTERNATIVE HYPOTHESIS (H1)
There is a meaningful difference between groups.
What we are trying to prove.

P-VALUE
Probability of observing results at least as extreme as actual results, assuming null hypothesis is true.

INTERPRETATION
- p less than 0.05: Statistically significant (95 percent confidence)
- p less than 0.01: Highly significant (99 percent confidence)
- p less than 0.10: Marginally significant (90 percent confidence)

TYPE I AND TYPE II ERRORS

TYPE I ERROR (False Positive)
- Rejecting null hypothesis when it is true
- Claiming a difference exists when it does not
- Probability = Alpha (typically 0.05 or 5 percent)

TYPE II ERROR (False Negative)
- Failing to reject null hypothesis when it is false
- Missing a real difference
- Probability = Beta (typically 0.20 or 20 percent)

RELATIONSHIP
- Reducing Type I error increases Type II error (and vice versa)
- Must balance based on business consequences
- False positives waste resources on ineffective changes
- False negatives miss valuable improvements

================================================================================
SECTION 3 - STATISTICAL POWER
================================================================================

DEFINITION
Power = 1 - Beta = Probability of detecting a true effect when it exists

STANDARD TARGET
80 percent power is conventional minimum (20 percent false negative rate)
90 percent power for high-stakes decisions

POWER DEPENDS ON
1. Sample size (larger = more power)
2. Effect size (larger effects easier to detect)
3. Significance level alpha (lower alpha = lower power)
4. Variance in data (less variance = more power)

POWER CALCULATION FORMULA
For two-sample comparison:
n = 2 x ((Z_alpha + Z_beta) / Effect_Size)^2 x Variance

Where:
- Z_alpha = 1.96 for 95 percent confidence (one-sided: 1.645)
- Z_beta = 0.84 for 80 percent power
- Effect_Size = Expected difference / Standard deviation

================================================================================
SECTION 4 - MINIMUM DETECTABLE EFFECT (MDE)
================================================================================

DEFINITION
The smallest effect size that can be reliably detected given sample size and power requirements.

FORMULA
MDE = (Z_alpha + Z_beta) x sqrt(2 x Variance / n)

PRACTICAL INTERPRETATION
- If MDE is 10 percent and true effect is 5 percent, test will likely miss it
- Choose sample size to achieve MDE smaller than expected effect

MDE TARGETS BY CONTEXT

CONVERSION RATE TESTS
- MDE of 5-10 percent relative lift typical
- Requires thousands to tens of thousands of conversions

REVENUE TESTS
- Higher variance requires larger samples
- MDE of 2-5 percent often achievable

ENGAGEMENT TESTS
- Lower variance allows smaller MDE
- MDE of 1-3 percent often achievable

================================================================================
SECTION 5 - SAMPLE SIZE CALCULATION
================================================================================

FOR CONVERSION RATE TESTS
n_per_group = 2 x p x (1 - p) x ((Z_alpha + Z_beta) / MDE)^2

EXAMPLE
- Baseline conversion rate: 3 percent
- Desired MDE: 10 percent relative (0.3 percent absolute)
- 95 percent confidence, 80 percent power

n = 2 x 0.03 x 0.97 x ((1.96 + 0.84) / 0.003)^2
n = approximately 50699 per group
Total sample needed: approximately 101400

FOR REVENUE TESTS
Higher variance requires larger adjustment.
Rule of thumb: 2-4x conversion test sample sizes.

================================================================================
SECTION 6 - CONFIDENCE INTERVALS
================================================================================

DEFINITION
Range within which true parameter value likely falls with specified probability.

95 PERCENT CONFIDENCE INTERVAL
CI = Point_Estimate +/- (1.96 x Standard_Error)

FOR PROPORTIONS
SE = sqrt(p x (1 - p) / n)
CI = p +/- 1.96 x sqrt(p x (1 - p) / n)

FOR DIFFERENCES
SE_diff = sqrt(SE_1^2 + SE_2^2)
CI_diff = (p1 - p2) +/- 1.96 x SE_diff

INTERPRETATION
If confidence interval for difference includes zero, difference is not statistically significant.

================================================================================
SECTION 7 - MULTIPLE TESTING CORRECTIONS
================================================================================

PROBLEM
Testing multiple metrics increases false positive rate.
With 20 metrics at alpha = 0.05, expect 1 false positive.

BONFERRONI CORRECTION
Adjusted_Alpha = Alpha / Number_of_Tests

EXAMPLE
Testing 5 metrics at 95 percent confidence:
Adjusted_Alpha = 0.05 / 5 = 0.01
Require p less than 0.01 for significance.

FALSE DISCOVERY RATE (FDR)
Benjamini-Hochberg procedure controls expected proportion of false positives among significant results.
Less conservative than Bonferroni.

HIERARCHICAL TESTING
1. Test primary metric first without adjustment
2. Only test secondary metrics if primary is significant
3. Apply correction only to secondary metrics

================================================================================
SECTION 8 - VALIDATION METHODOLOGY
================================================================================

PRE-TEST VALIDATION

A/A TEST
Run test with identical variants to verify no systematic bias.
Must show no significant difference.
Validates randomization and measurement.

SAMPLE RATIO MISMATCH (SRM)
Check that actual sample sizes match expected split.
Significant deviation indicates implementation problem.

FORMULA
Chi_Square = Sum of ((Observed - Expected)^2 / Expected)

POST-TEST VALIDATION

HOLDOUT VALIDATION
Reserve portion of data for validation.
Train model on 80 percent, validate on 20 percent.

CROSS-VALIDATION
K-fold cross-validation for more robust estimates.
Average performance across folds.

NOVELTY AND PRIMACY EFFECTS
Initial results may not persist.
Recommend 2-4 week observation for stable read.

================================================================================
SECTION 9 - STATISTICAL TESTING FORMULAS
================================================================================

Sample_Size = 2 x p x (1 - p) x ((Z_alpha + Z_beta) / MDE)^2
Statistical_Power = 1 - Beta
MDE = (Z_alpha + Z_beta) x sqrt(2 x Variance / n)
Standard_Error = sqrt(p x (1 - p) / n)
Confidence_Interval = Point_Estimate +/- (Z x Standard_Error)
Bonferroni_Alpha = Alpha / Number_of_Tests
Chi_Square_SRM = Sum of ((Observed - Expected)^2 / Expected)

================================================================================
COMPLIANCE NOTES
================================================================================

This document follows the 6-Rule Compliance Framework:

1. ALL-CAPS HEADERS: All section headers use uppercase
2. SIMPLE LISTS: Hyphens only for list items
3. ASCII ONLY: No special characters or unicode
4. ZERO VISUAL DEPENDENCIES: No images or complex formatting
5. MANDATORY LANGUAGE: Professional tone throughout
6. AGENT-READY: Decision logic and formulas included

================================================================================
END OF DOCUMENT
================================================================================
