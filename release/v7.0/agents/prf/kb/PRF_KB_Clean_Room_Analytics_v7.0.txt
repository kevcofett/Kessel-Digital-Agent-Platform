PRF KNOWLEDGE BASE - CLEAN ROOM ANALYTICS v1
VERSION: 1.0
STATUS: Production Ready
COMPLIANCE: 6-Rule Compliant

================================================================================
SECTION 1 - CLEAN ROOM FUNDAMENTALS
================================================================================

CLEAN ROOM DEFINITION

A data clean room is a secure environment where multiple parties can collaborate on data analysis without exposing underlying individual-level data to each other.

HOW CLEAN ROOMS WORK
1. Each party contributes encrypted data
2. Data matched on common identifiers
3. Analysis runs in secure environment
4. Only aggregated outputs exported
5. No raw data shared between parties

CLEAN ROOM BENEFITS
- Privacy-compliant data collaboration
- Access to walled garden data
- Cross-platform measurement
- Audience insights without data transfer
- Regulatory compliance

CLEAN ROOM PARTICIPANTS

DATA PROVIDERS
- Publishers with audience data
- Retailers with transaction data
- Platforms with engagement data
- Data vendors with enrichment

DATA USERS
- Advertisers seeking insights
- Agencies managing campaigns
- Brands analyzing performance
- Researchers conducting studies

================================================================================
SECTION 2 - CLEAN ROOM PROVIDERS
================================================================================

PLATFORM CLEAN ROOMS

GOOGLE ADS DATA HUB
- Access to Google campaign data
- BigQuery-based analysis
- Aggregation requirements enforced
- No individual-level export
- YouTube and GDN measurement

META ADVANCED ANALYTICS
- Facebook and Instagram data
- Privacy-safe analysis
- Conversion lift integration
- Limited query flexibility

AMAZON MARKETING CLOUD
- Amazon DSP and retail data
- Shopper insights
- Path to purchase analysis
- Audience building capabilities

INDEPENDENT CLEAN ROOMS

HABU
- Cloud-agnostic platform
- Multi-party collaboration
- Flexible matching options
- Advanced analytics capabilities

INFOSUM
- Decentralized architecture
- No data movement required
- Fast matching
- Strong privacy controls

LIVERAMP DATA COLLABORATION
- Identity resolution built-in
- Publisher network access
- Measurement use cases
- Activation capabilities

SNOWFLAKE DATA CLEAN ROOMS
- Native to Snowflake ecosystem
- SQL-based analysis
- Governance controls
- Broad data partner access

OPTABLE
- Publisher-focused
- Audience enrichment
- Activation support
- Privacy-by-design

PROVIDER SELECTION CRITERIA

TECHNICAL FACTORS
- Matching methodology
- Privacy controls
- Query flexibility
- Integration options
- Processing speed

BUSINESS FACTORS
- Partner network
- Pricing model
- Support quality
- Implementation complexity
- Use case fit

================================================================================
SECTION 3 - MATCHING AND IDENTITY
================================================================================

MATCHING METHODOLOGIES

DETERMINISTIC MATCHING
- Exact match on identifiers
- Hashed emails, phone numbers
- Highest accuracy
- Lower match rates

PROBABILISTIC MATCHING
- Statistical inference
- Multiple signals combined
- Higher match rates
- Lower individual accuracy

HYBRID MATCHING
- Deterministic where available
- Probabilistic to extend
- Balance of scale and accuracy
- Common in practice

IDENTIFIER TYPES

FIRST-PARTY IDENTIFIERS
- Hashed email (most common)
- Hashed phone number
- Customer ID
- Loyalty ID

PLATFORM IDENTIFIERS
- Google User ID
- Meta user identifiers
- Amazon customer ID
- Platform-specific tokens

UNIVERSAL IDENTIFIERS
- LiveRamp RampID
- Unified ID 2.0
- ID5
- Publisher-provided identifiers

MATCH RATE CONSIDERATIONS

TYPICAL MATCH RATES
- Email to platform: 40-60%
- Cross-platform: 30-50%
- Third-party data: 20-40%

IMPROVING MATCH RATES
- Use multiple identifiers
- Clean and standardize data
- Include multiple formats
- Update data regularly

MATCH RATE IMPACT
- Low match rates reduce sample size
- May introduce bias
- Consider representativeness
- Report match rates with results

================================================================================
SECTION 4 - USE CASES AND ANALYSIS
================================================================================

MEASUREMENT USE CASES

CROSS-PLATFORM ATTRIBUTION
- Combine data from multiple platforms
- Deduplicate conversions
- Understand customer journey
- More complete attribution

INCREMENTALITY ANALYSIS
- Combine exposed vs control data
- Calculate true lift
- Validate platform reporting
- Guide budget allocation

MEDIA MIX OPTIMIZATION
- Aggregate performance data
- Input to MMM models
- Cross-platform view
- Strategic planning

AUDIENCE USE CASES

AUDIENCE INSIGHTS
- Understand audience overlap
- Profile converter characteristics
- Identify high-value segments
- Inform targeting strategy

LOOKALIKE BUILDING
- Seed from customer data
- Find similar audiences
- Activate on platforms
- Expand reach efficiently

AUDIENCE SUPPRESSION
- Exclude existing customers
- Reduce wasted spend
- Privacy-compliant suppression
- Cross-platform consistency

RETAIL MEDIA USE CASES

CLOSED-LOOP MEASUREMENT
- Connect ad exposure to purchase
- Measure in-store sales lift
- Calculate true ROAS
- Optimize retail media spend

SHOPPER INSIGHTS
- Purchase behavior analysis
- Category trends
- Competitive analysis
- Product affinity

PATH TO PURCHASE
- Understand consideration journey
- Identify key touchpoints
- Optimize media timing
- Improve conversion

================================================================================
SECTION 5 - IMPLEMENTATION PROCESS
================================================================================

IMPLEMENTATION PHASES

PHASE 1 - PLANNING
- Define use cases
- Identify data requirements
- Select clean room provider
- Establish governance

PHASE 2 - DATA PREPARATION
- Data inventory
- Schema mapping
- Identity resolution prep
- Data quality checks

PHASE 3 - TECHNICAL SETUP
- Clean room configuration
- Data onboarding
- Matching validation
- Query testing

PHASE 4 - ANALYSIS
- Query development
- Output validation
- Insight generation
- Reporting setup

PHASE 5 - OPERATIONALIZATION
- Automate workflows
- Regular refresh schedule
- Monitoring and maintenance
- Continuous improvement

DATA PREPARATION REQUIREMENTS

DATA FORMATTING
- Consistent identifier format
- Standardized naming
- Clean data types
- Remove duplicates

PRIVACY PREPARATION
- Consent validation
- PII handling
- Retention policies
- Contractual requirements

QUALITY ASSURANCE
- Completeness check
- Accuracy validation
- Recency verification
- Consistency review

GOVERNANCE REQUIREMENTS

DATA USE AGREEMENTS
- Permitted use cases
- Output restrictions
- Data handling requirements
- Audit provisions

PRIVACY CONTROLS
- Minimum aggregation thresholds
- Differential privacy options
- Query approval workflows
- Access restrictions

COMPLIANCE DOCUMENTATION
- Data processing agreements
- Privacy impact assessments
- Consent documentation
- Regulatory compliance records

================================================================================
SECTION 6 - QUERY AND ANALYSIS PATTERNS
================================================================================

COMMON QUERY PATTERNS

OVERLAP ANALYSIS
- Count matched users between datasets
- Calculate overlap percentage
- Identify unique audiences
- Inform targeting strategy

AGGREGATE METRICS
- Sum, average, count by segment
- Performance metrics by audience
- Conversion rates by cohort
- Revenue by customer type

DISTRIBUTION ANALYSIS
- Frequency distributions
- Percentile analysis
- Cohort comparisons
- Time-based trends

FUNNEL ANALYSIS
- Conversion funnel by step
- Drop-off analysis
- Segment-level funnels
- Optimization opportunities

PRIVACY CONSTRAINTS

AGGREGATION MINIMUMS
- Minimum user count per output
- Typically 50-100 users minimum
- Platform-specific requirements
- Prevents re-identification

QUERY RESTRICTIONS
- No individual-level export
- Limited join operations
- Approved query templates
- Audit logging

DIFFERENTIAL PRIVACY
- Noise added to outputs
- Protects individual data
- Trade-off with precision
- Configurable epsilon values

REPORTING OUTPUTS

OUTPUT TYPES
- Aggregated statistics
- Segment-level insights
- Trend analysis
- Audience definitions (for activation)

OUTPUT FORMATS
- Dashboard visualizations
- CSV exports (aggregated)
- API integrations
- Automated reporting

INTERPRETATION GUIDANCE
- Understand privacy noise impact
- Report confidence intervals
- Note match rate context
- Document methodology

================================================================================
SECTION 7 - ACTIVATION FROM CLEAN ROOMS
================================================================================

ACTIVATION DEFINITION

Using clean room insights to build and target audiences on advertising platforms.

ACTIVATION APPROACHES

INSIGHT-BASED ACTIVATION
- Generate insights in clean room
- Build targeting rules from insights
- Apply rules in ad platforms
- No data transfer required

AUDIENCE EXPORT
- Build audience in clean room
- Export as platform audience
- Activate on platform
- Privacy controls maintained

PLATFORM-NATIVE ACTIVATION
- Analysis and activation in one
- Amazon Marketing Cloud example
- Seamless workflow
- Platform-specific audiences

ACTIVATION USE CASES

PROSPECTING AUDIENCES
- Lookalikes from seed data
- High-propensity prospects
- Category intenders
- Competitive conquesting

RETARGETING AUDIENCES
- Lapsed customers
- High-value segments
- Product affinity groups
- Purchase stage segments

SUPPRESSION AUDIENCES
- Recent purchasers
- Low-value customers
- Unsubscribed users
- Competitive exclusions

ACTIVATION BEST PRACTICES

AUDIENCE SIZE REQUIREMENTS
- Minimum for activation varies by platform
- Typically 1,000+ users minimum
- Larger audiences more stable
- Consider refresh frequency

REFRESH CADENCE
- Dynamic audiences need regular updates
- Weekly or monthly typical
- Real-time where possible
- Monitor audience size changes

MEASUREMENT OF ACTIVATED AUDIENCES
- Track performance vs standard targeting
- Calculate incrementality where possible
- Measure audience quality
- Iterate based on results

================================================================================
SECTION 8 - AGENT APPLICATION GUIDANCE
================================================================================

CLEAN ROOM RECOMMENDATION CRITERIA

RECOMMEND CLEAN ROOMS WHEN
- Need cross-platform measurement
- Want to access walled garden data
- Require privacy-compliant collaboration
- Have sufficient data volume

DO NOT RECOMMEND WHEN
- Limited budget (high setup cost)
- Simple measurement needs
- Insufficient data volume
- Lack of technical resources

PROVIDER RECOMMENDATIONS

FOR GOOGLE MEASUREMENT
- Google Ads Data Hub
- Access to YouTube and GDN
- BigQuery skills required

FOR META MEASUREMENT
- Meta Advanced Analytics
- Limited but useful
- Platform-specific insights

FOR RETAIL MEDIA
- Amazon Marketing Cloud
- Retailer-specific rooms
- Closed-loop measurement

FOR MULTI-PARTY COLLABORATION
- Habu or InfoSum
- Maximum flexibility
- Higher implementation effort

BUDGET GUIDANCE

TYPICAL COSTS
- Platform clean rooms: Often included in ad spend
- Independent providers: $50,000-200,000+ annually
- Implementation services: $25,000-100,000+
- Ongoing analysis: Internal resources required

ROI CONSIDERATIONS
- Measurement improvement value
- Media efficiency gains
- Audience quality improvement
- Strategic insight value

IMPLEMENTATION TIMELINE

TYPICAL TIMELINE
- Planning: 2-4 weeks
- Setup: 4-8 weeks
- Initial analysis: 2-4 weeks
- Operationalization: 4-8 weeks
- Total: 3-6 months for full implementation

SUCCESS FACTORS
- Executive sponsorship
- Clear use cases
- Quality data
- Technical resources
- Partner cooperation

WARNING SIGNS
- Low match rates (below 30%)
- Insufficient sample sizes
- Unclear value proposition
- Governance gaps
- Partner misalignment

================================================================================
END OF DOCUMENT
================================================================================
